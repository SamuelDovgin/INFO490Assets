{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Data, Machines and the üêç\n",
    "<img src=\"https://raw.githubusercontent.com/NSF-EC/INFO490Assets/master/src/dmap/lessons/word-vectors/html/section00.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"install\"></a>\n",
    "## Notebook Preparation for Lesson\n",
    "Each lesson will start with a template (given in the course schedule).  \n",
    "Once you open the notebook:\n",
    "1. **save** in on your google drive (copy to drive) and share the notebook\n",
    "2. **copy** the share ID to the `NOTEBOOK_ID` (and re-save the notebook)\n",
    "3. **run** the next cell to install the IDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After changing NOTEBOOK_ID to the shared ID\n",
    "# 1. SAVE THE NOTEBOOK cmd+s\n",
    "# 2. Re-RUN this code cell\n",
    "NOTEBOOK_ID  = '1GBamwb67eCSPp0YreXMIrFF-IZOT1nT3'  # change me!!\n",
    "LESSON_ID    = 'dmap:text:word-vectors'       # keep this as is\n",
    "VERSION_ID   = 25\n",
    "\n",
    "def install_ide(lesson_id, nb_id, reload=True):\n",
    "  import os\n",
    "  if not os.path.exists('Bootstrap.py'):\n",
    "     !wget 'https://raw.githubusercontent.com/NSF-EC/INFO490Assets/master/src/tools/Bootstrap.py' -O Bootstrap.py > out.txt 2>&1 \n",
    "  try:\n",
    "    import Bootstrap, importlib\n",
    "    importlib.reload(Bootstrap)\n",
    "\n",
    "    boot = Bootstrap.BootStrap()\n",
    "    return boot.create_ide(lesson_id, nb_id, reload)\n",
    "  except Exception as e:\n",
    "    class Nop(object):\n",
    "        def __init__(self, e): self.e = e\n",
    "        def nop(self, *args, **kw): return(\"unable to test:\" + self.e, None)\n",
    "        def __getattr__(self, _): return self.nop \n",
    "    class IDE():\n",
    "      tester=Nop(str(e))\n",
    "      reader=Nop(str(e)) # RemoteReader ??\n",
    "    return IDE()\n",
    "\n",
    "ide = install_ide(LESSON_ID, NOTEBOOK_ID)\n",
    "ide.tester.hello_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson Word Embeddings\n",
    "\n",
    "(run the next cell to read the first part of the lesson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words as Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "try:\n",
    "  print('installing model, please wait')\n",
    "  import en_core_web_md  # don't use lg (too big)\n",
    "except ImportError:\n",
    "  print('need to download .. please wait')\n",
    "  !python -m spacy download en_core_web_md\n",
    "  import en_core_web_md \n",
    "\n",
    "nlp = en_core_web_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve words from the English model vocabulary\n",
    "cat = nlp.vocab['cat']\n",
    "dog = nlp.vocab['dog']\n",
    "car = nlp.vocab['car']\n",
    "\n",
    "# print the dimension of word vectors\n",
    "print('vector length:', len(cat.vector))\n",
    "\n",
    "# print the word vector\n",
    "print('cat:', cat.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The similarity between dog and dog:', dog.similarity(dog))\n",
    "print('The similarity between dog and car:', dog.similarity(car))\n",
    "print('The similarity between dog and cat:', dog.similarity(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(a, b):\n",
    "    return 0\n",
    "    \n",
    "print(sim(dog,car))\n",
    "# or use the tester: print(ide.tester.test_fn(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim2(a,b):\n",
    "  return np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "  \n",
    "man = nlp.vocab['father'].vector\n",
    "woman = nlp.vocab['mother'].vector\n",
    "d1 = man - woman\n",
    "\n",
    "uncle = nlp.vocab['uncle'].vector\n",
    "aunt = nlp.vocab['aunt'].vector\n",
    "d2 = uncle - aunt\n",
    "\n",
    "print(sim2(d1, d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, topn=10):\n",
    "\n",
    "    # get all words in the vocabulary\n",
    "    allwords = [w for w in nlp.vocab if w.has_vector and w.is_lower and w.lower_ != word.lower_]  \n",
    "    \n",
    "    # sort words by similarity in descending order\n",
    "    out = sorted(allwords, key=lambda w: word.similarity(w), reverse=True)  \n",
    "    return out[:topn]\n",
    "\n",
    "neighbors = most_similar(car)\n",
    "print([w.text for w in neighbors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(v, exclude):\n",
    "\n",
    "  cos = lambda v1, v2: np.dot(v1, v2)/(np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "  # valid ensures we don't include any of the words \n",
    "  # that are part of the equation (input)\n",
    "  def valid(w, exclude):\n",
    "    if w.has_vector and w.is_lower:\n",
    "      for t in exclude:\n",
    "        if w.lower_.find(t)>=0:\n",
    "          return False\n",
    "      return True\n",
    "    return False\n",
    "\n",
    "  w_set = [w for w in nlp.vocab if valid(w, exclude)]\n",
    "  candidates = sorted(w_set, key=lambda w: cos(result, w.vector), reverse=True)\n",
    "  return candidates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimensions(labels):\n",
    "  from sklearn.manifold import TSNE\n",
    "  import numpy as np\n",
    "  \n",
    "  data = np.array([nlp.vocab[w].vector for w in labels])\n",
    "  # reduce to two\n",
    "  tsne_model = TSNE(n_components=2)\n",
    "  data_2d = tsne_model.fit_transform(data)\n",
    "  \n",
    "  return data_2d\n",
    "\n",
    "def plot_results(data_2d, labels):\n",
    "  import matplotlib\n",
    "  import matplotlib.pyplot as plt\n",
    "  \n",
    "  # plot the 2d vectors and show their labels\n",
    "  fig, axes = plt.subplots()\n",
    "  axes.scatter(data_2d[:, 0], data_2d[:, 1], s=100)\n",
    "  for i, txt in enumerate(labels):\n",
    "    axes.annotate(txt, (data_2d[i,0], data_2d[i,1]), xytext=(2, 3), textcoords='offset points')\n",
    "  axes.grid()\n",
    "  \n",
    "  return fig\n",
    "\n",
    "labels = ['king', 'man', 'queen', 'woman']\n",
    "data = reduce_dimensions(labels)\n",
    "fig = plot_results(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogy(three_words, nlp):\n",
    "   return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test and Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to read the next section\n",
    "ide.reader.view_section(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ide.tester.test_notebook()) \n",
    "# print(ide.tester.test_notebook(verbose=True)) \n",
    "\n",
    "ide.tester.download_solution()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "AB",
   "collapsed_sections": [],
   "count": 25,
   "name": "Word Embeddings",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
