<!DOCTYPE html><html lang='en'><head><title>TF•IDF (part 2)</title><meta charset="utf-8"><style>/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:.67em 0}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}strong{font-weight:bolder}code{font-family:monospace,monospace;font-size:1em}img{border-style:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}h1,h2,h3,p,pre{margin:0}ol{list-style:none;margin:0;padding:0}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e2e8f0}img{border-style:solid}h1,h2,h3{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}code,pre{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}img{display:block;vertical-align:middle}img{max-width:100%;height:auto}.bg-gray-200{--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.border-green-500{--border-opacity:1;border-color:#48bb78;border-color:rgba(72,187,120,var(--border-opacity))}.border-2{border-width:2px}.float-left{float:left}.font-serif{font-family:Georgia,Cambria,"Times New Roman",Times,serif}.text-xl{font-size:1.25rem}.mt-0{margin-top:0}.mt-2{margin-top:.5rem}.mr-2{margin-right:.5rem}.mb-2{margin-bottom:.5rem}.mr-3{margin-right:.75rem}.max-w-sm{max-width:24rem}.max-w-2xl{max-width:42rem}.p-1{padding:.25rem}.p-3{padding:.75rem}.pl-3{padding-left:.75rem}.lesson{padding-left:10px;padding-right:10px;--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}p.new{padding-top:.5em;padding-bottom:.5em}h1,h2,h3{font-weight:700;margin-bottom:.5em;font-family:Georgia,Cambria,"Times New Roman",Times,serif!important}h1{margin-top:1.5em;font-size:2em!important}h2{margin-top:1em;font-size:1.5em!important}h3{margin-top:.5em;font-size:1.25em!important}p.new a{text-decoration:underline}img:not([class]){width:66.666667%;margin-left:1.25rem;border:1px solid #021a40}pre code{font-size:15px}p code{font-size:smaller}.code-large{background:#f4f4f4;font-family:monospace;font-size:15px;margin:10px;font-size:15px}pre code:not(.line-number){background:#f4f4f4;font-family:monospace;font-size:15px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:default;touch-action:none;-webkit-touch-callout:none;-webkit-tap-highlight-color:transparent;border:1px solid #ddd;color:#666;page-break-inside:avoid;display:block;min-width:740px;max-width:740px;line-height:1.6;margin-bottom:1.6em;padding:1em 1.5em;-moz-tab-size:2;-o-tab-size:2;tab-size:2;overflow-x:auto;word-wrap:break-word;white-space:pre-wrap;border-left:3px solid #f36d33}div.code-starter>pre code{border-left:3px solid #fdff44!important;background-image:radial-gradient(rgba(0,150,0,.75),#000 120%);color:#fff;font:.9rem Inconsolata,monospace}div.code-starter>pre code::after{content:"\a$_"}pre{counter-reset:line}
div.code-starter {display:none;}</style><script src="https://kit.fontawesome.com/7efc4bcee2.js" crossOrigin="anonymous"></script></head><body class="lesson"><div class="main-content bg-gray-200 p-1 pl-3 text-xl font-serif"><div class="md-inner"><div class="ide code-starter blink"><pre><code>def cv_demo_tf_idf():

    doc_term_matrix, tokens = cv_demo2()
    tfidf_transformer=TfidfTransformer(smooth_idf=True)

    # learn the IDF vector
    tfidf_transformer.fit(doc_term_matrix)
    idf = tfidf_transformer.idf_

    # transform the count matrix to tf-idf
    tf_idf_vector = tfidf_transformer.transform(doc_term_matrix)

    # print out the values 
    # for the token 'i' in the second document
    token = 'i'
    doc = 1
    df_idf = pd.DataFrame(idf, index=tokens, columns=["idf_weights"])
    df_idf.sort_values(by=['idf_weights'], inplace=True, ascending=False)
    idf_token = df_idf.loc[token]['idf_weights']

    doc_vector = tf_idf_vector[doc]
    df_tfidf = pd.DataFrame(doc_vector.T.todense(), index=tokens, columns=["tfidf"])
    df_tfidf.sort_values(by=["tfidf"], ascending=False, inplace=True)
    tfidf_token = df_tfidf.loc[token]['tfidf']

    # tfidf = tf * idf
    tf_token = tfidf_token / idf_token
    print('TF    {:s} {:2.4f}'.format(token, tf_token))
    print('IDF   {:s} {:2.4f}'.format(token, idf_token))
    print('TFIDF {:s} {:2.4f}'.format(token, tfidf_token))</code></pre></div><p class="new">Once you run the code you should see the following for the second document, token 'i':</p><pre><code>TF    i 0.3165
IDF   i 1.5108
TFIDF i 0.4781</code></pre><p class="new">However, in the previous lesson (with the updated IDF formula), you will see the following:</p><pre><code>TF:     0.1875
IDF:    1.5108
TFIDF:  0.28328</code></pre><p class="new">[❌] Matching TF (NO!!!)</p><p class="new">Since the IDF values match, and we can only really see the end result (TF•IDF), we can infer that the 
issue (two actually) must be with the TF formula.</p><h3 id="tf-formula-">TF Formula </h3><p class="new">By default sklearn is using the raw term counts.  You can adjust this slightly by setting the named paremter 
<code>sublinear_tf=True</code>.  This changes the formula to 1 + math.log(tf) where tf is the number of occurances
of the term in the document.</p><p class="new">We used a normalized term count (which was divided by the length of the document).  There's no option
in sklearn for this option.  So let's update our TF calculation to be the following:</p><p class="new">1 + math.log(tf) to match sci-kit learn's.</p><p class="new">Where <strong>tf</strong> is the count of how many times term appear in the current document</p><h3 id="normalization">Normalization</h3><p class="new">By Default, the final TF•IDF calculations are normalized using the L2 norm (a.k.a. Euclidian).<br/>The L2 norm is just the square root of the sum of the squared vector values:</p><img alt="math?math=%5CLarge%20v_%7Bnorm%7D%20%3D%20%5Cfrac%7Bv%7D%7B%7C%7Cv%7C%7C_2%7D%20%3D%20%5Cfrac%7Bv%7D%7B%5Csqrt%7Bv_1%5E2%20%2B%20v_2%5E2%20%2B%20%5Cdots%20%2B%20v_n%5E2%7D%7D" class="jax" src="https://render.githubusercontent.com/render/math?math=%5CLarge%20v_%7Bnorm%7D%20%3D%20%5Cfrac%7Bv%7D%7B%7C%7Cv%7C%7C_2%7D%20%3D%20%5Cfrac%7Bv%7D%7B%5Csqrt%7Bv_1%5E2%20%2B%20v_2%5E2%20%2B%20%5Cdots%20%2B%20v_n%5E2%7D%7D"/><p class="new">As an example, let's look at how L2 normalization is done using TF•IDF values for the word 'I':</p><pre><code>L2_norm = sqrt(tfidf('am')²    + tfidf('and')² + .. + tfidf('i')² + ..  +
               tfidf('would')² + tfidf('you')²)

tfidf_norm('i') = tfidf('i')/L2_norm</code></pre><p class="new">The nice thing about applying L2 normalization is that it puts different features on the same scale.<br/>Also, mathmatically, the L2 Norm of the resulting normalized values is 1.0.  That is if you took the square root 
of the sum of the squared tfidif norm values (e.g. <code>tfidf_norm('i')</code>), it would be 1.0.</p><p class="new">The L1 norm uses the sum of the absolute values (a.k.a. Manhattan distance).  We will see more examples in the future of using 
L2 normalization.  A closely related topic, L2 regularization will be discussed later as well.</p><p class="new">We will NOT do this to our code in the previous lesson -- it would require a lot of code refactoring.  Instead, we 
will turn normalization off when we create a <code>TfidfTransformer</code>.</p><p class="new">In order to turn off normalization (remember out goal is to get sklearn's output to match our output from
the previous lesson), we can set the norm parameter to None:</p><pre><code>tfidf_transformer=TfidfTransformer(smooth_idf=True, sublinear_tf=True, norm=None)</code></pre><p class="new">Now we should see the following after running <code>cv_demo_tf_idf</code>. These numbers will match the output
of your code in the previous lesson if you made to two respective changes.</p><pre><code>TF    i 2.0986
IDF   i 1.5108
TFIDF i 3.1706</code></pre><p class="new">[✅] Matching IDF<br/>[✅] Matching TF</p><img alt="tfidf-geah.png" src="https://github.com/NSF-EC/INFO490Assets/raw/master/src/dmap/lessons/tfidf-skl/html/tfidf-geah.png"/></div></div></body></html>