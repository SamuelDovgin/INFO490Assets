<!DOCTYPE html><html lang='en'><head><title>TF•IDF (part 2)</title><meta charset="utf-8"><style>/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:.67em 0}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}strong{font-weight:bolder}code{font-family:monospace,monospace;font-size:1em}img{border-style:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}h1,h2,h3,p,pre{margin:0}ol{list-style:none;margin:0;padding:0}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e2e8f0}img{border-style:solid}h1,h2,h3{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}code,pre{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}img{display:block;vertical-align:middle}img{max-width:100%;height:auto}.bg-gray-200{--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.border-green-500{--border-opacity:1;border-color:#48bb78;border-color:rgba(72,187,120,var(--border-opacity))}.border-2{border-width:2px}.float-left{float:left}.font-serif{font-family:Georgia,Cambria,"Times New Roman",Times,serif}.text-xl{font-size:1.25rem}.mt-0{margin-top:0}.mt-2{margin-top:.5rem}.mr-2{margin-right:.5rem}.mb-2{margin-bottom:.5rem}.mr-3{margin-right:.75rem}.max-w-sm{max-width:24rem}.max-w-2xl{max-width:42rem}.p-1{padding:.25rem}.p-3{padding:.75rem}.pl-3{padding-left:.75rem}.lesson{padding-left:10px;padding-right:10px;--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}p.new{padding-top:.5em;padding-bottom:.5em}h1,h2,h3{font-weight:700;margin-bottom:.5em;font-family:Georgia,Cambria,"Times New Roman",Times,serif!important}h1{margin-top:1.5em;font-size:2em!important}h2{margin-top:1em;font-size:1.5em!important}h3{margin-top:.5em;font-size:1.25em!important}p.new a{text-decoration:underline}img:not([class]){width:66.666667%;margin-left:1.25rem;border:1px solid #021a40}pre code{font-size:15px}p code{font-size:smaller}.code-large{background:#f4f4f4;font-family:monospace;font-size:15px;margin:10px;font-size:15px}pre code:not(.line-number){background:#f4f4f4;font-family:monospace;font-size:15px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:default;touch-action:none;-webkit-touch-callout:none;-webkit-tap-highlight-color:transparent;border:1px solid #ddd;color:#666;page-break-inside:avoid;display:block;min-width:740px;max-width:740px;line-height:1.6;margin-bottom:1.6em;padding:1em 1.5em;-moz-tab-size:2;-o-tab-size:2;tab-size:2;overflow-x:auto;word-wrap:break-word;white-space:pre-wrap;border-left:3px solid #f36d33}div.code-starter>pre code{border-left:3px solid #fdff44!important;background-image:radial-gradient(rgba(0,150,0,.75),#000 120%);color:#fff;font:.9rem Inconsolata,monospace}div.code-starter>pre code::after{content:"\a$_"}pre{counter-reset:line}
div.code-starter {display:none;}</style><script src="https://kit.fontawesome.com/7efc4bcee2.js" crossOrigin="anonymous"></script></head><body class="lesson"><div class="main-content bg-gray-200 p-1 pl-3 text-xl font-serif"><div class="md-inner"><div class="ide code-starter blink"><pre><code>import pandas as pd

def word_matrix_to_df(wm, feature_names):
    # create an index for each row
    doc_names = ['Doc{:d}'.format(idx+1) for idx, _ in enumerate(wm)]
    df = pd.DataFrame(data=wm.toarray(), index=doc_names, columns=feature_names)
    return df

def cv_demo3():

    doc_term_matrix, tokens = cv_demo2()
    df = word_matrix_to_df(doc_term_matrix, tokens)
    
    return df

df = cv_demo3()
print(df.head())</code></pre></div><p class="new">You should see data that matches the table below:
<img alt="tfidf-cv.png" class="mt-2 mr-3 sm" src="https://github.com/NSF-EC/INFO490Assets/raw/master/src/dmap/lessons/tfidf-skl/html/tfidf-cv.png"/></p><p class="new">Take a look at sklearn's <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer">documentation</a>.
The <code>CountVectorizer</code> allows you to customize many of the parsing routines:</p><pre><code>cvec = CountVectorizer(tokenizer=split_into_tokens,  # custom tokenizer
                       ngram_range=(1, 2),   # both single and bi-grams
                       stop_words=['and', 'but'])   # custom stop words</code></pre><h2 id="tfidftransformer"><code>TfidfTransformer</code></h2><p class="new">Now that we have a vector of word counts, we can transform those into a TF•IDF matrix (essentially the 
same process as the previous lesson).</p><pre><code>from sklearn.feature_extraction.text import TfidfTransformer
def cv_demo_idf():
    
    # get the data from the CountVectorizer
    doc_term_matrix, tokens = cv_demo2()
    
    # create a transformer
    tfidf_transformer=TfidfTransformer()
    
    # transform the doc_term_matrix into TF*IDF
    tfidf_transformer.fit(doc_term_matrix)

    # make it a dataframe for easy viewing
    df = pd.DataFrame(tfidf_transformer.idf_,
                      index=tokens, columns=["idf_weights"])
    # sort ascending
    df.sort_values(by=['idf_weights'], inplace=True, ascending=False)

    return df

df = cv_demo_idf()
print(df.head(20))</code></pre><p class="new">Type in the code above and run it in the next code cell.</p></div></div></body></html>