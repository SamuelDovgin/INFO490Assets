<!DOCTYPE html><html lang='en'><head><title>TF•IDF (part 2)</title><meta charset="utf-8"><style>/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:.67em 0}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}strong{font-weight:bolder}code{font-family:monospace,monospace;font-size:1em}img{border-style:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}h1,h2,h3,p,pre{margin:0}ol{list-style:none;margin:0;padding:0}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e2e8f0}img{border-style:solid}h1,h2,h3{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}code,pre{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}img{display:block;vertical-align:middle}img{max-width:100%;height:auto}.bg-gray-200{--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.border-green-500{--border-opacity:1;border-color:#48bb78;border-color:rgba(72,187,120,var(--border-opacity))}.border-2{border-width:2px}.float-left{float:left}.font-serif{font-family:Georgia,Cambria,"Times New Roman",Times,serif}.text-xl{font-size:1.25rem}.mt-0{margin-top:0}.mt-2{margin-top:.5rem}.mr-2{margin-right:.5rem}.mb-2{margin-bottom:.5rem}.mr-3{margin-right:.75rem}.max-w-sm{max-width:24rem}.max-w-2xl{max-width:42rem}.p-1{padding:.25rem}.p-3{padding:.75rem}.pl-3{padding-left:.75rem}.lesson{padding-left:10px;padding-right:10px;--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}p.new{padding-top:.5em;padding-bottom:.5em}h1,h2,h3{font-weight:700;margin-bottom:.5em;font-family:Georgia,Cambria,"Times New Roman",Times,serif!important}h1{margin-top:1.5em;font-size:2em!important}h2{margin-top:1em;font-size:1.5em!important}h3{margin-top:.5em;font-size:1.25em!important}p.new a{text-decoration:underline}img:not([class]){width:66.666667%;margin-left:1.25rem;border:1px solid #021a40}pre code{font-size:15px}p code{font-size:smaller}.code-large{background:#f4f4f4;font-family:monospace;font-size:15px;margin:10px;font-size:15px}pre code:not(.line-number){background:#f4f4f4;font-family:monospace;font-size:15px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:default;touch-action:none;-webkit-touch-callout:none;-webkit-tap-highlight-color:transparent;border:1px solid #ddd;color:#666;page-break-inside:avoid;display:block;min-width:740px;max-width:740px;line-height:1.6;margin-bottom:1.6em;padding:1em 1.5em;-moz-tab-size:2;-o-tab-size:2;tab-size:2;overflow-x:auto;word-wrap:break-word;white-space:pre-wrap;border-left:3px solid #f36d33}div.code-starter>pre code{border-left:3px solid #fdff44!important;background-image:radial-gradient(rgba(0,150,0,.75),#000 120%);color:#fff;font:.9rem Inconsolata,monospace}div.code-starter>pre code::after{content:"\a$_"}pre{counter-reset:line}
div.code-starter {display:none;}</style><script src="https://kit.fontawesome.com/7efc4bcee2.js" crossOrigin="anonymous"></script></head><body class="lesson"><div class="main-content bg-gray-200 p-1 pl-3 text-xl font-serif"><div class="md-inner"><h1 class="section" id="section4">Clustering and Distance Document Simularity</h1><p class="new">now that we have a matrix where the rows are documents (document vectors) of normalized tf*idf values
we can easily compare two documents and see how similar (or different they are).</p><p class="new">The distance between two document vectors is the essence behind using tf*idf for document clustering (an unsupervised machine
learning algorithm), as well as trying to retrived releent documents by search terms.  Your search terms become
a 'document' which gets converted to a vector which can easily find other document vectors that are close to it.</p><p class="new">.... <a href="http://brandonrose.org/clustering#Tf-idf-and-document-similarity">http://brandonrose.org/clustering#Tf-idf-and-document-similarity</a></p><p class="new">attributes 
# TO BE USED
ADD TIMING Section</p><p class="new">TF: It is the number of times the word appears in a document (not the relative freq)</p><ol start="1"><li>• Use the following formula (discussed in detail soon) to calculate the idf of 
a term: <code class="large"><p class="new">term_idf[term] = 1 + log( (N + 1)/(1 + doc_term_count))</p></code></li></ol><h2 id="protecting-the-math-">Protecting The Math </h2><p class="new">At first glance, it might seem 'easy' to calculate TF•IDF (we are almost there). However, for 
both weights there are different ways to calculate them.   The TF we have been describing is 
called the raw count of a term in a document.  A common alternative  is to scale the TF by the 
document length so that long documents don't skew the results (e.g. a long chapter will have 
more words in it, but may be no more important than a shorter chapter). </p><code class="code-large">TF = (raw count of term in a document)/len(document)</code><p class="new">For IDF, there are many variants as well.  The one issue for calculating IDF is that the 
denominator could be zero (if a term does not show up in a document).  In most situations, 
all the terms are coming from the documents themselves, so this can never happen.  </p><p class="new">Some implementations will calculate the 'inverse' going from this equation: </p><code class="code-large">term_idf[term] = log(N/term_count)</code><br/><p class="new">to this equation:<br/><code class="code-large">term_idf[term] = -1.0 * log(term_count/N)

</code><br/></p><p class="new">If you remember your 'log' rules (here's a small 'proof' for the right hand side):<br/><span><img alt="math?math=%5Clarge%201.%5Cquad%20log(%5Cdfrac%7Ba%7D%7Bb%7D)%20%3D%20log(a)%20-%20log(b)" class="jax" src="https://render.githubusercontent.com/render/math?math=%5Clarge%201.%5Cquad%20log(%5Cdfrac%7Ba%7D%7Bb%7D)%20%3D%20log(a)%20-%20log(b)" style="display:inline-block"/> (by definition)

</span><br/><span><img alt="math?math=%5Clarge%202.%5Cquad%20log(%5Cdfrac%7Bb%7D%7Ba%7D)%20%3D%20log(b)%20-%20log(a)" class="jax" src="https://render.githubusercontent.com/render/math?math=%5Clarge%202.%5Cquad%20log(%5Cdfrac%7Bb%7D%7Ba%7D)%20%3D%20log(b)%20-%20log(a)" style="display:inline-block"/> (by definition)

</span><br/><span><img alt="math?math=%5Clarge%203.%5Cquad%20log(a)%20%3D%20log(b)%20-%20log(%5Cdfrac%7Bb%7D%7Ba%7D)" class="jax" src="https://render.githubusercontent.com/render/math?math=%5Clarge%203.%5Cquad%20log(a)%20%3D%20log(b)%20-%20log(%5Cdfrac%7Bb%7D%7Ba%7D)" style="display:inline-block"/> (rearrange terms in #2)

</span><br/><span><img alt="math?math=%5Clarge%204.%5Cquad%20log(a)%20-%20log(b)%20%3D%20-log(%5Cdfrac%7Bb%7D%7Ba%7D)" class="jax" src="https://render.githubusercontent.com/render/math?math=%5Clarge%204.%5Cquad%20log(a)%20-%20log(b)%20%3D%20-log(%5Cdfrac%7Bb%7D%7Ba%7D)" style="display:inline-block"/> (rearrange terms in #3)

</span><br/><strong>SO</strong><br/><span><img alt="math?math=%5Clarge%205.%5Cquad%20log(%5Cdfrac%7Ba%7D%7Bb%7D)%20%3D%20-1.0%20%5Ctimes%20log(%5Cdfrac%7Bb%7D%7Ba%7D)" class="jax" src="https://render.githubusercontent.com/render/math?math=%5Clarge%205.%5Cquad%20log(%5Cdfrac%7Ba%7D%7Bb%7D)%20%3D%20-1.0%20%5Ctimes%20log(%5Cdfrac%7Bb%7D%7Ba%7D)" style="display:inline-block"/></span><br/></p><p class="new">Some will add 1 to the result or to the denominator (to set a lower bound on common words and 
avoid giving a weight of zero to common terms) or both.</p><p class="new">For the most part, if your documents are long and the number of terms large, the calculation will not 
matter for comparison purposes.  However, for simple test data, it can matter.  In practice, everyone 
seems to have their favorite tweaks to the classic formula. </p><p class="new">The Python library <code>sklearn</code> (coming just around the corner) uses the formula you are usingin <code>build_idf</code>.</p><p class="new">  TIMING CODE</p></div></div></body></html>