<!DOCTYPE html><html lang='en'><head><title>Machine Learning</title><meta charset="utf-8"><style>/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:.67em 0}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}strong{font-weight:bolder}code{font-family:monospace,monospace;font-size:1em}img{border-style:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}blockquote,h1,h2,h3,h4,p,pre{margin:0}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e2e8f0}img{border-style:solid}h1,h2,h3,h4{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}code,pre{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}img{display:block;vertical-align:middle}img{max-width:100%;height:auto}.bg-gray-200{--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.bg-gray-300{--bg-opacity:1;background-color:#e2e8f0;background-color:rgba(226,232,240,var(--bg-opacity))}.bg-blue-200{--bg-opacity:1;background-color:#bee3f8;background-color:rgba(190,227,248,var(--bg-opacity))}.bg-blue-300{--bg-opacity:1;background-color:#90cdf4;background-color:rgba(144,205,244,var(--bg-opacity))}.border-gray-400{--border-opacity:1;border-color:#cbd5e0;border-color:rgba(203,213,224,var(--border-opacity))}.border-gray-500{--border-opacity:1;border-color:#a0aec0;border-color:rgba(160,174,192,var(--border-opacity))}.rounded{border-radius:.25rem}.rounded-full{border-radius:9999px}.border-solid{border-style:solid}.border{border-width:1px}.border-t{border-top-width:1px}.inline-block{display:inline-block}.inline{display:inline}.flex{display:flex}.justify-center{justify-content:center}.justify-around{justify-content:space-around}.float-right{float:right}.float-left{float:left}.clear-both{clear:both}.font-serif{font-family:Georgia,Cambria,"Times New Roman",Times,serif}.font-semibold{font-weight:600}.font-bold{font-weight:700}.h-64{height:16rem}.text-xs{font-size:.75rem}.text-sm{font-size:.875rem}.text-base{font-size:1rem}.text-xl{font-size:1.25rem}.m-2{margin:.5rem}.my-3{margin-top:.75rem;margin-bottom:.75rem}.mt-1{margin-top:.25rem}.mt-2{margin-top:.5rem}.mr-2{margin-right:.5rem}.mb-2{margin-bottom:.5rem}.mr-3{margin-right:.75rem}.mb-3{margin-bottom:.75rem}.mt-4{margin-top:1rem}.mt-6{margin-top:1.5rem}.max-w-sm{max-width:24rem}.max-w-2xl{max-width:42rem}.object-contain{-o-object-fit:contain;object-fit:contain}.overflow-hidden{overflow:hidden}.p-1{padding:.25rem}.py-1{padding-top:.25rem;padding-bottom:.25rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.px-3{padding-left:.75rem;padding-right:.75rem}.py-4{padding-top:1rem;padding-bottom:1rem}.px-4{padding-left:1rem;padding-right:1rem}.px-6{padding-left:1.5rem;padding-right:1.5rem}.pl-3{padding-left:.75rem}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.05)}.shadow-inner{box-shadow:inset 0 2px 4px 0 rgba(0,0,0,.06)}.text-left{text-align:left}.text-center{text-align:center}.text-black{--text-opacity:1;color:#000;color:rgba(0,0,0,var(--text-opacity))}.text-gray-700{--text-opacity:1;color:#4a5568;color:rgba(74,85,104,var(--text-opacity))}.text-gray-800{--text-opacity:1;color:#2d3748;color:rgba(45,55,72,var(--text-opacity))}.whitespace-no-wrap{white-space:nowrap}.w-1\/2{width:50%}.w-full{width:100%}.text-tiny{font-size:.5rem!important}body{color:#000!important;font-size:1.25rem!important}.lesson{padding-left:10px!important;padding-right:10px!important;--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.lesson-footer{margin-top:50px;margin-top:20px}span{white-space:nowrap}p.new{padding-top:0;padding-bottom:.5em;text-indent:1.25em}h1,h2,h3,h4{font-weight:700;margin-bottom:.25em;font-family:Georgia,Cambria,"Times New Roman",Times,serif!important}h1{margin-top:.5em;font-size:2em!important;clear:both;color:#000!important}h2{margin-top:1em;font-size:1.5em!important;clear:both;color:#8b0000!important}h3{margin-top:.5em;font-size:1.25em!important;clear:both;color:#006400!important}h4{margin-top:.25em;font-size:1em!important;clear:both;color:#00008b!important}p.new a{text-decoration:underline}.lesson a{text-decoration:underline}blockquote{font-size:1em;background:#f9f9f9;border-left:10px solid #ccc;margin:.5em 10px;padding:.5em 10px;border-left-color:#ffcd69;border-right-color:#f6ba59;quotes:"\201C""\201D""\2018""\2019"}blockquote:before{color:#ccc;content:open-quote;font-size:4em;line-height:.1em;margin-right:.25em;vertical-align:-.4em}blockquote p{display:inline}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.5)}img.large{width:83.333333%;-o-object-position:center;object-position:center;margin-left:auto;margin-right:auto;border:1px solid #021a40}img.border{border:1px solid #021a40}img.iw600{height:auto;width:auto;max-width:600px}img.iw400{height:auto;width:auto;max-width:400px}img.iw300{height:auto;width:auto;max-width:300px}code{font-size:smaller}pre code{font-size:15px}pre code:not(.line-number){background:#f4f4f4;font-family:monospace;font-size:15px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:default;touch-action:none;-webkit-touch-callout:none;-webkit-tap-highlight-color:transparent;clear:both;border:1px solid #ddd;color:#666;page-break-inside:avoid;display:block;min-width:740px;max-width:740px;line-height:1.6;margin-bottom:1.6em;padding:1em 1.5em;-moz-tab-size:2;-o-tab-size:2;tab-size:2;overflow-x:auto;word-wrap:break-word;white-space:pre-wrap;border-left:3px solid #f36d33}pre{counter-reset:line}</style><script src="https://kit.fontawesome.com/7efc4bcee2.js" crossOrigin="anonymous"></script></head><body class="lesson"><div class="main-content bg-gray-200 text-black p-1 pl-3 font-serif"><div class="md-inner">
<h1 class="overview"></h1><div class="lesson-overview bg-gray-200 flex justify-center"><div class="text-center px-4 py-2 m-2"><div class="displaycard bg-blue-200 max-w-sm rounded overflow-hidden shadow-lg"><div>¬†</div><img alt="Text" class="object-contain h-64 w-full" src="https://github.com/NSF-EC/INFO490Assets/raw/master/src/dmap/lessons/mlprep/html/MachineLearningV1-sm.png"/><div class="px-6 py-4"><div class="text-center font-bold text-xl">Machine Learning</div><p class="text-center text-gray-800 text-xl">Prepping for ML</p><div class="text-gray-700 text-base">¬†</div><div class="text-center mb-3"><span class="inline-block bg-gray-300 rounded-full px-3 py-1 text-sm font-semibold text-gray-700 mr-2">#machine learning</span></div><div class="flex border-t border-solid border-gray-500 shadow-inner justify-around bg-blue-300"><div class="text-gray-700 text-center px-4 m-2 text-sm"><span class="whitespace-no-wrap">D.MÔπ†üêç</span></div><div class="text-gray-700 text-center px-4 m-2 text-sm"><span class="whitespace-no-wrap"><strong>Version:</strong> <!-- -->8/21/2020</span></div></div><div class="text-gray-700 mt-1 text-center text-tiny">All Rights Reserved</div></div></div></div><div class="text-center px-4 py-2 m-2 w-1/2"><div class="displaycard bg-gray-200 max-w-sm rounded overflow-hidden shadow-lg"><div class="px-6 py-4 text-left"><div class="text-center font-bold text-xl">Machine Learning<br/>prerequisites</div><div class="text-center text-xs mb-2">(start only after finishing)</div><p class="max-w-sm text-gray-800 text-sm">‚¶ø <strong>info490</strong></p></div><div class="px-6 py-4 text-left text-gray-800"><div class="text-center font-bold text-xl">Colab Notes</div><p class="max-w-sm text-sm">1. <strong>Copy</strong> this notebook into your google drive</p><p class="max-w-sm text-sm">2. <strong>Share</strong> the notebook, and copy the share ID</p><p class="max-w-sm text-sm">3. <strong>Set</strong> the NOTEBOOK_ID variable to the share ID</p><p class="max-w-sm text-gray-800 text-sm">4. <strong>SAVE</strong> the notebook (‚åò/ctrl+ s) again</p><p class="max-w-sm text-gray-800 text-sm">5. <strong>Run</strong> the code cell that installs the INFO 490 IDE</p><div class="text-center font-bold text-xl">¬†</div><div class="text-center font-bold text-xl">Jupyter/PyCharm Notes</div><p class="max-w-sm text-gray-800 text-sm text-left">The testing framework does <strong>not work</strong> (at this time) for Jupyter  notebooks or local code development.</p></div></div></div></div><h1 class="section" id="section1">Machine Learning</h1><p class="new">In the 80's (the previous century), <strong>AI</strong> (or artificial intelligence) was the 'hot ' 
word in technology.  In the 1990's and early 2000's, it was <strong>Data Mining</strong>. 
In 2010, anything around <strong>Data Science</strong> started to explode.  Today, 
it's <strong>Machine Learning</strong> (and its partner <strong>Deep Learning</strong>).  Much of all this 'hype' is actually
 closely related and this lesson attempts to unravel a bit of all the words you
 have most likely have heard -- but not quite sure how they all fit.</p><p class="new">Almost everything we have done so far has looked like the image below:</p><img alt="modelA.png" class="my-3 large iw600" src="https://github.com/NSF-EC/INFO490Assets/raw/master/src/dmap/lessons/mlprep/html/modelA.png"/><p class="new">That is, we, the data scientist, created a program (or a set of functions). 
That program is then given some input and it produces some answer/output. The 
idea behind machine learning (ML for short) is that we still create a program
that is given data.  However, that program's output is another program (usually
called a model):
<img alt="modelB.png" class="my-3 large iw600" src="https://github.com/NSF-EC/INFO490Assets/raw/master/src/dmap/lessons/mlprep/html/modelB.png"/>That program/model is then given some input/data and then an answer/output is
 produced.</p><h2 id="the-black-box-and-model-confusion">The Black Box and ‚ùì‚ùìModel‚ùì‚ùì Confusion</h2><img alt="blackBox.png" class="float-left border mr-3" src="https://github.com/NSF-EC/INFO490Assets/raw/master/src/dmap/lessons/mlprep/html/blackBox.png"/><p class="new">In almost all cases, the output produced (the program) cannot be 'read' by 
a human to understand exactly what is happening; hence, it is usually referred to as a black box.
 Neural networks (more about these later) -- especially deep neural
  networks are notorious for being obtuse and impenetrable.</p><p class="new">The word 'model' is <em>usually</em> used to refer to this black box (the output of 
the ML algorithm).  However, the word 'model' is ALSO used to reference the
ML algorithm itself.  For example, you may read about 'how to select the 
best model' (a reference to the algorithm used) or how to train the model (a
 reference to the output produced) or as a reference a specific mathematical 
 or probabilistic representation about the relationship between various 
 data attributes (a reference to the output).  We will attempt to use the word 
 model as a reference to the output of the ML algorithm. 
<br class="clear-both"/></p><h2 id="learning-from-data">Learning from Data</h2><p class="new">The word <strong>learning</strong> in this context means that the algorithm performs better
as more data is given to it.  There are many formal definitions of ML, but it 
basically means the performance improves (i.e. learns, makes less mistakes, 
has a lower error rate) with more experience.  Experience is based on seeing and
processing more data (or having more examples).  </p><blockquote><p class="new">Tom Mitchell (one of ML's pioneers) provides the following definition: <br/>‚ÄúA computer program 
is said to learn from experience E with respect to some class of 
tasks T and performance measure P, 
if its performance at tasks in T, as measured by P, 
improves with experience E.‚Äù</p></blockquote><p class="new">One of <em>the</em> most important aspects of ML is that the quality of the model 
generated depends almost entirely on both the quality and quantity of the
 data.  The term <strong>big data</strong> is just a reference to the fact that some of
  these algorithms need a lot of data.  So much data in fact, that 
  understanding how to manage and use 'big data' have emerged as subfields
   and careers.</p><h3 id="training-the-model--learning">Training the Model == Learning</h3><p class="new">Many of the ML algorithms involve iterations through the same data.  After
the algorithm processes all the data, an evaluation is made as to it's
 performance (correctness, minimization of loss or risk).  Adjustments 
 are made (more on this later) and the process starts over. This process is usually referred as
  'training' the model.  It is how it "learns".</p><h2 id="goals-and-data">Goals And Data</h2><img alt="ML.png" class="inline mr-3 float-left" src="https://github.com/NSF-EC/INFO490Assets/raw/master/src/dmap/lessons/mlprep/html/ML.png"/><p class="new">Much of our learning about ML (and teaching) involves trying to understand, 
organize and categorize the types of algorithms one can use to build a model.<br/>The selection of what type of ML algorithm to use can depend on both the
 goals of the project (e.g is it to predict, group/cluster, find patterns) as well as the 
 available data that can be used to create and train the model.  We will 
 focus on using the three most common categories of ML algorithms:  supervised, unsupervised, 
 and reinforcement learning.  You may have even come across these words
  several times.  Let's go over each.</p><h3 id="labelled-and-unlabelled-data">Labelled (and unlabelled) Data</h3><p class="new">Understanding the nature of the data has a major impact in what kind of machine 
learning can be done.  One of the important aspects is whether the
 data is 'labelled'.  For labelled data, the data itself has a field/attribute 
that identifies or 'labels' the data (sometimes referred to as the target).</p><h4 id="independent-dependent-variables">independent dependent variables</h4><p class="new">Another way</p><p class="new">Another way to think about this is whether or not your data has a dependent
 variable or not.  This dependent variable is considered the 'label'. For 
 example, if you had a database of images, each image could be 'labeled' that 
identifies the type of object/thing in the image.  The label could also
 indicate if the image has a specific characteristic or not.  As another
  example, if you had a list of borrowers' attributes for a loan program, your label 
might be whether or not a load was given to that person.  If you're 
trying to predict something from your data, each instance (e.g. row) of 
the data is marked. </p><h4 id="who-labels-the-data">Who labels the data?</h4><p class="new">Most labelled data comes from humans (e.g. students or a <a href="https://www.mturk.com/get-started" target="_blank">mechanical turk</a>). 
However, some data can be labelled by a end result of a process (e.g. the
 result of whether or not a student was admitted, a loan given, etc). </p><h1 class="section" id="section2">Supervised Machine Learning </h1><p class="new">For most <strong>supervised</strong> ML algorithms/techniques there is a notion of knowing
what the answer should be.  Hence, almost all supervised ML algorithms use
 labelled data. The goal of the ML algorithm can be to determine how the 
 independent variables can be combined to predict the dependent variable or
 to figure out how to correctly predict the label based on seeing all the 
 other attributes of the data.  </p><img alt="ClassVSRegTrans.png" class="inline mr-3 float-left" src="https://github.com/NSF-EC/INFO490Assets/raw/master/src/dmap/lessons/mlprep/html/ClassVSRegTrans.png"/><p class="new">A few popular types of Supervised ML are regression and classification. Both
attempt to predict the target/dependent variable; in regression it's a numeric 
value (i.e. continuous) and in classification it's a category (i.e. discrete). </p><p class="new">We will discuss each in future lessons.</p><br/><h1 class="section" id="section3">Unsupervised Learning</h1><img alt="220px-K-means_convergence.gif" class="mr-3 float-left border" src="https://github.com/NSF-EC/INFO490Assets/raw/master/src/dmap/lessons/mlprep/html/220px-K-means_convergence.gif"/><p class="new">For <strong>unsupervised</strong> ML algorithms, the goal is to discover patterns and 
structures in the data.  Since the data is NOT labelled, classified (pictured
 to the left) or assigned a target, there is no 'right' answer.  As you can imagine, one of
 the issues with unsupervised learning is determining the appropriate 
 performance metric. </p><p class="new">A few examples of these algorithms include clustering, association rules,
  dimensionality reduction, EM, outlier and anomaly detection</p><h1 class="section" id="section4">Reinforcement Learning</h1><p class="new">One of the issues with both supervised and unsupervised learning is that the
performance of the model can never be BETTER than the data.  That is
if our goal was to be better at classifying images than the humans who 
labelled the data, we could never get there.</p><p class="new"><strong>Reinforcement</strong> learning refers to goal-oriented algorithms which learn how to attain a complex objective (goal) or how to 
maximize along a particular dimension over many steps. For example, 
if you wanted your model to learn how to play pong or chess and actually
become better at the game, reinforcement learning would be part of it. </p><h2 id="pong-from-pixels">Pong From Pixels</h2><p class="new">Reinforcement learning uses the concepts of agents, environments, 
states, actions, feedback and rewards.  We are NOT going to go into
details (if any); however, a good paper/blog that shows how reinforcement 
learning was used to build a system to play <a href="http://karpathy.github.io/2016/05/31/rl/" target="_blank">pong</a>.
Reinforcement learning is a very active field in ML.</p><h1 class="section" id="section5">Topics, Terms and Concepts</h1><img alt="iceberg.png" class="mr-3 my-3 float-left border iw300" src="https://github.com/NSF-EC/INFO490Assets/raw/master/src/dmap/lessons/mlprep/html/iceberg.png"/><p class="new">The world of machine learning sits on a giant mountain (or iceberg).<br/>There are semester based courses and careers that focus on very specific areas.  It's a large and expanding
 field and our goal is to get you comfortable knowing the space and where to explore next.  Let's go
 over a few concepts that are part of the ML lexicon.</p><h2 id="neural-networks">Neural Networks</h2><img alt="NN.png" class="mr-3 my-3 float-right border iw400" src="https://github.com/NSF-EC/INFO490Assets/raw/master/src/dmap/lessons/mlprep/html/NN.png"/><p class="new">As popular as neural networks are, you may have found it interesting that
it wasn't mentioned in the big three areas just discussed.  </p><p class="new">Both Supervised (your data has labels) where you are trying to build a function
approxiamator ... to help classify or predict
function approximation</p><p class="new">OR build interesting relationships and patterns.<br/>Word Emededdings are a good example of Unsupervised Learning.</p><p class="new">NN have an enoramouse vocabulary as well.
Things like feed forward, back propogration, graident descent, irecurrent, 
.. ao=.... </p><h2 id="deep-learning">Deep Learning</h2><p class="new">Deep learning is a class of machine learning algorithms that uses 
multiple layers to progressively extract higher level features from the 
raw input.  Much of deep learning is closely associated with deep neural
 networks.  A Deep NN is just a NN with multiple layers.</p><h2 id="semi-supervised-learning">Semi Supervised Learning</h2><p class="new">What</p><h2 id="overfitting">overfitting</h2><p class="new"> We need to be careful to build a robust 
 model such that we can give it new data (data without a label) and predict
  one for it.  The ideas of overfitting where the model uses invalid, 
  impractical or noisy attributes to perfectly fit the data need to be 
  addressed.  Imagine a model that predicated eye color based on the name of
   the subject rather than the genes of the parents.</p><pre><code>def predict_eyecolor(data):
   if data.name == 'bob':
      return 'blue'
   if data.name == 'jean':
      return 'green'
   if data.name == 'nancy':
      return 'brown'
   if data.name == 'mike':
      return 'blue'
   #.... 10000 more statements like this</code></pre><p class="new">That 'model', although has 100% predication rate, would fail (most likely) on 
new unforeseen data.</p><p class="new">For supervised learning, we know the correct answer.  The goal of the</p><h1 class="section" id="section6">Lesson Assignment</h1><p class="new">You can breath easily for this one.  There is nothing to hand in.  However
the content in this lesson is rich for quizzes.  But more importantly, this
lesson lays the foundation of trying to build a map of how to organize the
 world of machine learning.</p><div class="lesson-footer flex bg-gray-200 justify-center"><div class="displaycard bg-blue-200 border-t border-gray-400 max-w-2xl rounded overflow-hidden shadow-lg"><div class="px-6 py-4"><div class="text-center font-bold text-xl">Machine Learning</div><p class="text-center text-gray-800 text-xl">Prepping for ML</p><div class="text-center mt-6 text-xl"><i aria-hidden="true" class="fas fa-tags"></i> any questions on Piazza with <span class="font-bold">ml-prep</span></div><div class="text-gray-700 text-base">¬†</div><div></div><div class="flex mt-4 border-t border-solid border-gray-500 justify-around bg-gray-200"><div class="text-gray-700 text-center px-4 m-2 text-sm">D.MÔπ†üêç</div><div class="text-gray-700 text-center px-4 m-2 text-sm"><strong>Version:</strong> <!-- -->8/21/2020, 11:31:52 AM</div></div><div class="text-gray-700 mt-2 text-center text-tiny">All Rights Reserved</div><div class="text-gray-700 text-center text-tiny">Do not distribute this notebook outside of the class</div></div></div></div></div></div></body></html>