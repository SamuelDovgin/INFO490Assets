<!DOCTYPE html><html lang='en'><head><title>TF•IDF</title><meta charset="utf-8"><style>/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:.67em 0}pre{font-family:monospace,monospace;font-size:1em}strong{font-weight:bolder}code{font-family:monospace,monospace;font-size:1em}img{border-style:none}input{font-family:inherit;font-size:100%;line-height:1.15;margin:0}input{overflow:visible}[type=checkbox]{box-sizing:border-box;padding:0}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}h1,h2,p,pre{margin:0}ol{list-style:none;margin:0;padding:0}html{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,::after,::before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e2e8f0}img{border-style:solid}input:-ms-input-placeholder{color:#a0aec0}input::-ms-input-placeholder{color:#a0aec0}input::-webkit-input-placeholder{color:#a0aec0}input::-moz-placeholder{color:#a0aec0}h1,h2{font-size:inherit;font-weight:inherit}input{padding:0;line-height:inherit;color:inherit}code,pre{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}img{display:block;vertical-align:middle}img{max-width:100%;height:auto}.container{width:100%}@media (min-width:640px){.container{max-width:640px}}@media (min-width:768px){.container{max-width:768px}}@media (min-width:1024px){.container{max-width:1024px}}@media (min-width:1280px){.container{max-width:1280px}}.bg-gray-200{--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.bg-gray-300{--bg-opacity:1;background-color:#e2e8f0;background-color:rgba(226,232,240,var(--bg-opacity))}.bg-orange-300{--bg-opacity:1;background-color:#fbd38d;background-color:rgba(251,211,141,var(--bg-opacity))}.bg-green-200{--bg-opacity:1;background-color:#c6f6d5;background-color:rgba(198,246,213,var(--bg-opacity))}.border-gray-400{--border-opacity:1;border-color:#cbd5e0;border-color:rgba(203,213,224,var(--border-opacity))}.border-gray-500{--border-opacity:1;border-color:#a0aec0;border-color:rgba(160,174,192,var(--border-opacity))}.border-indigo-500{--border-opacity:1;border-color:#667eea;border-color:rgba(102,126,234,var(--border-opacity))}.rounded{border-radius:.25rem}.rounded-full{border-radius:9999px}.border-solid{border-style:solid}.border-l-2{border-left-width:2px}.border-t{border-top-width:1px}.cursor-pointer{cursor:pointer}.block{display:block}.inline-block{display:inline-block}.flex{display:flex}.justify-center{justify-content:center}.justify-around{justify-content:space-around}.float-left{float:left}.font-sans{font-family:system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji"}.font-serif{font-family:Georgia,Cambria,"Times New Roman",Times,serif}.font-semibold{font-weight:600}.font-bold{font-weight:700}.h-64{height:16rem}.text-sm{font-size:.875rem}.text-base{font-size:1rem}.text-xl{font-size:1.25rem}.leading-normal{line-height:1.5}.m-2{margin:.5rem}.mt-0{margin-top:0}.mt-1{margin-top:.25rem}.mt-2{margin-top:.5rem}.mr-2{margin-right:.5rem}.mt-3{margin-top:.75rem}.mr-3{margin-right:.75rem}.mb-3{margin-bottom:.75rem}.ml-3{margin-left:.75rem}.mt-4{margin-top:1rem}.mt-6{margin-top:1.5rem}.max-w-sm{max-width:24rem}.max-w-2xl{max-width:42rem}.max-w-4xl{max-width:56rem}.object-contain{-o-object-fit:contain;object-fit:contain}.opacity-0{opacity:0}.overflow-hidden{overflow:hidden}.p-1{padding:.25rem}.p-3{padding:.75rem}.py-1{padding-top:.25rem;padding-bottom:.25rem}.px-3{padding-left:.75rem;padding-right:.75rem}.py-4{padding-top:1rem;padding-bottom:1rem}.px-4{padding-left:1rem;padding-right:1rem}.px-6{padding-left:1.5rem;padding-right:1.5rem}.pl-3{padding-left:.75rem}.absolute{position:absolute}.shadow-md{box-shadow:0 4px 6px -1px rgba(0,0,0,.1),0 2px 4px -1px rgba(0,0,0,.06)}.shadow-lg{box-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -2px rgba(0,0,0,.05)}.text-center{text-align:center}.text-gray-700{--text-opacity:1;color:#4a5568;color:rgba(74,85,104,var(--text-opacity))}.text-gray-800{--text-opacity:1;color:#2d3748;color:rgba(45,55,72,var(--text-opacity))}.whitespace-no-wrap{white-space:nowrap}.w-2\/3{width:66.666667%}.w-full{width:100%}@media (min-width:768px){.md\:w-2\/3{width:66.666667%}}.text-tiny{font-size:.5rem!important}.lesson{padding-left:10px;padding-right:10px;--bg-opacity:1;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity))}.lesson-footer{margin-top:50px;margin-top:20px}p.new{padding-top:.5em;padding-bottom:.5em}.h-18rem{height:17rem}h1,h2{font-weight:700;margin-bottom:.5em;font-family:Georgia,Cambria,"Times New Roman",Times,serif!important}h1{margin-top:1.5em;font-size:2em!important}h2{margin-top:1em;font-size:1.5em!important}pre code{font-size:15px}p code{font-size:smaller}.code{background:#f4f4f4;font-family:monospace;font-size:15px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:default;touch-action:none;-webkit-touch-callout:none;-webkit-tap-highlight-color:transparent;border:1px solid #ddd;color:#666;page-break-inside:avoid;display:block;min-width:740px;max-width:740px;line-height:1.6;margin-bottom:1.6em;padding:1em 1.5em;-moz-tab-size:2;-o-tab-size:2;tab-size:2;overflow-x:auto;word-wrap:break-word;white-space:pre-wrap;border-left:3px solid #f36d33!important}pre code:not(.line-number){background:#f4f4f4;font-family:monospace;font-size:15px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;cursor:default;touch-action:none;-webkit-touch-callout:none;-webkit-tap-highlight-color:transparent;border:1px solid #ddd;color:#666;page-break-inside:avoid;display:block;min-width:740px;max-width:740px;line-height:1.6;margin-bottom:1.6em;padding:1em 1.5em;-moz-tab-size:2;-o-tab-size:2;tab-size:2;overflow-x:auto;word-wrap:break-word;white-space:pre-wrap;border-left:3px solid #f36d33}div.code-starter>pre code{border-left:3px solid #fdff44!important;background-image:radial-gradient(rgba(0,150,0,.75),#000 120%);color:#fff;font:.9rem Inconsolata,monospace}div.code-starter>pre code::after{content:"\a$_"}pre{counter-reset:line}code.line-number{counter-increment:line}code.line-number::before{padding:0 .5em;margin-right:.5em;border-right:1px solid #ddd}code.line-number:before{content:"0" counter(line)}code.line-number:nth-child(n+10):before{content:counter(line)}.tab{font-size:1rem;border-color:#8c6728}.tab-content{max-height:0;transition:max-height .35s}.tab input:checked~.tab-content{max-height:100vh}.tab input:checked+label{padding:1rem;border-left-width:2px;border-color:#6574cd;background-color:#f8fafc;color:#6574cd}.tab label::after{float:right;right:0;top:0;display:block;width:1em;height:1.5em;line-height:1.5;font-size:1rem;text-align:center;transition:all .35s}.tab input[type=checkbox]+label::after{content:"+";font-weight:700;border-width:1px;border-radius:9999px;border-color:#8c6728}.tab input[type=checkbox]:checked+label::after{transform:rotate(315deg);background-color:#6574cd;color:#f8fafc}
div.code-starter {display:none;}</style><script src="https://kit.fontawesome.com/7efc4bcee2.js" crossOrigin="anonymous"></script></head><body class="lesson"><div class="main-content bg-gray-200 p-1 pl-3 text-xl font-serif"><div class="md-inner"><div class="ide code-starter blink"><pre><code>import LessonUtil as Util

def get_corpus():

    c1 = "Do you like Green eggs and ham"
    c2 = "I do not like them Sam I am  I do not like Green eggs and ham"
    c3 = "Would you like them Here or there"
    c4 = "I would not like them Here or there I would not like them Anywhere"
    return [c1, c2, c3, c4]
    
def split_into_tokens(data, normalize=True, min_length=0):

   # returns an array of words
   # each word is simply a string
  
   # splits the incoming data (a string) based on white-space
   # if normalize is True, normalize the case of the words
   # only return those words/tokens longer than min_length
   return []
  
def test_split():
  corpus   = get_corpus()
  doc1     = corpus[0]
  print(split_into_tokens(doc1))
  
test_split()

# also, use the test framework to test
# ide.tester.test_function(split_into_tokens)</code></pre></div><h2 id="tf">TF</h2><p class="new">We have already been calculating TF (term frequency) since we started working with Python dictionaries and 
counting word occurrences.  So for us, TF would describe the frequency of a word within a document; it 
measures how common a term is within a document.  It is the ratio of number of times the word 
appears in a document compared to the total number of words in that document:</p><img alt="math?math=%5CLarge%20%5Ctext%7B%0Atf(t%2Cd)%20%3D%20(count%20of%20term%20t%20in%20document%20d)%20%2F%20(number%20of%20words%20in%20document%20d)%0A%7D%0A" class="jax" src="https://render.githubusercontent.com/render/math?math=%5CLarge%20%5Ctext%7B%0Atf(t%2Cd)%20%3D%20(count%20of%20term%20t%20in%20document%20d)%20%2F%20(number%20of%20words%20in%20document%20d)%0A%7D%0A"/><img alt="math?math=%5CHuge%20tf_%7Bt%2Cd%7D%20%3D%20%5Cdfrac%7Bn_%7Bt%2Cd%7D%7D%7B%5Csum_%7B%7D%5E%7B%7D%20n_%7Bt%2Cd%7D%7D" class="mt-3 mb-3" src="https://render.githubusercontent.com/render/math?math=%5CHuge%20tf_%7Bt%2Cd%7D%20%3D%20%5Cdfrac%7Bn_%7Bt%2Cd%7D%7D%7B%5Csum_%7B%7D%5E%7B%7D%20n_%7Bt%2Cd%7D%7D"/><ol start="1"><li>• <img alt="math?math=%5CLarge%20n_%7Bt%2Cd%7D" class="jax" src="https://render.githubusercontent.com/render/math?math=%5CLarge%20n_%7Bt%2Cd%7D" style="display:inline-block"/> (the numerator) is the number of times term <strong>t</strong> appears 
in document <strong>d</strong>.</li><li>• Each document has its own TF.</li><li>• A term can be an n-gram as well.</li></ol><p class="new">For this lesson, we will implement the TF data structure as a list of dictionaries (actually <code>collections.Counter</code>).
Each counter (i.e document) associates the word (the key) to it count (the value).<br/>For this example, <code>tf[1]['like']</code> would be the TF for the first document
for the word 'like' (i.e. 2/len(document1)). </p><p class="new">In the following code cell, implement the function named <code>build_tf</code></p><pre><code>import collections

def build_tf(corpus, min_length=0):

   # corpus is an list of documents
   # a document is an unparsed string of words
   
   # returns a tuple with two items:
   # first item is a collections.Counter 
   # for all the words (&gt; min_length) in the corpus
   vocab = collections.Counter
   tfs = None 
  
   # the second item is the TF array, one for each document
   # each TF is a collection.Counter, 
   # each counter maps a word to the relative frequency 
   # of each word in that document 
   
   return  vocab, tfs</code></pre><p class="new">A few notes.</p><ol start="1"><li>• Use <img alt="math?math=%5Clarge%20tf_%7Bt%2Cd%7D%20%3D%20%5Cdfrac%7Bn_%7Bt%2Cd%7D%7D%7B%5Csum_%7B%7D%5E%7B%7D%20n_%7Bt%2Cd%7D%7D" class="jax" src="https://render.githubusercontent.com/render/math?math=%5Clarge%20tf_%7Bt%2Cd%7D%20%3D%20%5Cdfrac%7Bn_%7Bt%2Cd%7D%7D%7B%5Csum_%7B%7D%5E%7B%7D%20n_%7Bt%2Cd%7D%7D" style="display:inline-block"/></li><li>• Each TF is a collections.Counter, as is the corpus vocabulary</li><li>• <code>vocab['eggs']/len(vocab)</code> is frequency of 'eggs' across all documents (chapters)</li><li>• <code>tf[0]['eggs']</code> is the relative frequency of 'eggs' in the first document (chapter)</li></ol></div></div></body></html>